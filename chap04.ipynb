{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da43e42",
   "metadata": {},
   "source": [
    "# 4. テキストを生成するための GPT モデルを一から実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf6b92",
   "metadata": {},
   "source": [
    "## 4.1 LLM アーキテクチャのコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece1c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "  \"vocab_size\": 50257,\n",
    "  \"context_length\": 1024,\n",
    "  \"emb_dim\": 768,\n",
    "  \"n_heads\": 12,\n",
    "  \"n_layers\": 12,\n",
    "  \"drop_rate\": 0.1,\n",
    "  \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e24a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT プレースホルダモデルアーキテクチャ\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    self.trf_blocks = nn.Sequential(\n",
    "      *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "    )\n",
    "\n",
    "    self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "    self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "  def forward(self, in_idx):\n",
    "    batch_size, seq_len = in_idx.shape\n",
    "    tok_embeds = self.tok_emb(in_idx)\n",
    "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "    x = tok_embeds + pos_embeds \n",
    "    x = self.drop_emb(x)\n",
    "    x = self.trf_blocks(x)\n",
    "    x = self.final_norm(x)\n",
    "    logits = self.out_head(x)\n",
    "    return logits\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "\n",
    "  def __init__(self, normalized_shape, eps=1e-5):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037607e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every ca holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92bbcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250ec82a",
   "metadata": {},
   "source": [
    "## 4.2 層正規化を使って活性化を正規化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb268ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113f604",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n:\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf71658",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 層正規化クラス\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "  def __init__(self, emb_dim):\n",
    "    super().__init__()\n",
    "    self.eps = 1e-5\n",
    "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean = x.mean(dim=-1, keepdim=True)\n",
    "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "    norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "    return self.scale * norm_x + self.shift \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2df418",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\",var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fccac",
   "metadata": {},
   "source": [
    "## 4.3 GELU活性化を使ってフィードフォワードネットワークを実装する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GELU活性化関数\n",
    "class GELU(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi))* (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8,3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "  plt.subplot(1, 2, i)\n",
    "  plt.plot(x, y)\n",
    "  plt.title(f\"{label} activete function\")\n",
    "  plt.xlabel(\"x\")\n",
    "  plt.ylabel(f\"{label}(x)\")\n",
    "  plt.grid(True)\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fba01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# フィードフォワードニューラルネットワークモジュール\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "      GELU(),\n",
    "      nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6bf6c",
   "metadata": {},
   "source": [
    "## 4.4 ショートカット接続を追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list 4.5 ショートカット接続を追加したニューラルネットワーク\n",
    "\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "  def __init__(self, layer_sizes, use_shortcut):\n",
    "    super().__init__()\n",
    "    self.use_shortcut = use_shortcut\n",
    "\n",
    "    self.layers = nn.ModuleList([\n",
    "      nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "      nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "      nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "      nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "      nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
    "    ])\n",
    "\n",
    "  def forward(self, x):\n",
    "    for layer in self.layers:\n",
    "      layer_output = layer(x)\n",
    "      if self.use_shortcut and x.shape == layer_output.shape:\n",
    "        x = x + layer_output\n",
    "      else:\n",
    "        x = layer_output\n",
    "    return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09323c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "  output = model(x)\n",
    "  target = torch.tensor([[0.]])\n",
    "\n",
    "  loss = nn.MSELoss()\n",
    "  loss = loss(output, target)\n",
    "\n",
    "  loss.backward()\n",
    "\n",
    "  for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "      print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)\n",
    "\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea73b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36716e4",
   "metadata": {},
   "source": [
    "## 4.5 Transformer ブロックで Attention 層と線形層を接続する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34db87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list 4-6 \n",
    "\n",
    "from MultiHeadAttention import MultiHeadAttention\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    self.att = MultiHeadAttention(\n",
    "      d_in=cfg[\"emb_dim\"], d_out=cfg[\"emb_dim\"], context_length=cfg[\"context_length\"],\n",
    "      num_heads=cfg[\"n_heads\"], dropout=cfg[\"drop_rate\"], qkv_bias=cfg[\"qkv_bias\"]\n",
    "    )\n",
    "    self.ff = FeedForward(cfg)\n",
    "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "  def forward(self, x):\n",
    "    shortcut = x\n",
    "    x = self.norm1(x)\n",
    "    x = self.att(x)\n",
    "    x = self.drop_shortcut(x)\n",
    "    x = x + shortcut\n",
    "\n",
    "    shortcut = x\n",
    "    x = self.norm2(x)\n",
    "    x = self.ff(x)\n",
    "    x = self.drop_shortcut(x)\n",
    "    x = x + shortcut\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1915dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a60b961",
   "metadata": {},
   "source": [
    "## 4.6 GTP モデルを実装する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eab5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 4-7\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    self.trf_blocks = nn.Sequential(\n",
    "      *[TransformerBlock(cfg) for _ in range (cfg[\"n_layers\"])]\n",
    "    )\n",
    "\n",
    "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "    self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "  def forward(self, in_idx):\n",
    "    batch_size, seq_len = in_idx.shape\n",
    "    tok_embeds = self.tok_emb(in_idx)\n",
    "\n",
    "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "    x = tok_embeds + pos_embeds\n",
    "    x = self.drop_emb(x)\n",
    "    x = self.trf_blocks(x)\n",
    "    x = self.final_norm(x)\n",
    "    logits = self.out_head(x)\n",
    "    return logits\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9063fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters : {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e82d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
