{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e9ef54",
   "metadata": {},
   "source": [
    "# 5. ラベルなしでの事前学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78778679",
   "metadata": {},
   "source": [
    "## 5.1 生成テキストモデルを評価する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c387c06",
   "metadata": {},
   "source": [
    "### GPTを使ってテキストを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2813e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPTModel import GPTModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from GPTModel import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "  \"vocab_size\": 50257,\n",
    "  \"context_length\": 256,\n",
    "  \"emb_dim\": 768,\n",
    "  \"n_heads\": 12,\n",
    "  \"n_layers\": 12,\n",
    "  \"drop_rate\": 0.1,\n",
    "  \"qkv_bias\": False,  \n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1353b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 5-1\n",
    "\n",
    "import tiktoken\n",
    "from util import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "  encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dim\n",
    "  return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "  flat = token_ids.squeeze(0) # remove batch dim.\n",
    "  return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "  model=model,\n",
    "  idx=text_to_token_ids(start_context, tokenizer),\n",
    "  max_new_tokens=10,\n",
    "  context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9d192e",
   "metadata": {},
   "source": [
    "### テキスト生成の損失を計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,     1107, 588]])  #  \"I really like\"]\n",
    "targets = torch.tensor ([[3626, 6100, 345],   # [\" effort moves you\",\n",
    "                         [1107, 588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim= -1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e0325",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc08e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_idx = 0\n",
    "target_brabs_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_brabs_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_brabs_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_brabs_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probas = torch.log(torch.cat((target_brabs_1, target_brabs_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef1ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12885e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89322ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87060b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9518b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82809d",
   "metadata": {},
   "source": [
    "### 訓練データセットと検証データセットで損失を計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507327b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "  text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx   = int(train_ratio * len(text_data))\n",
    "train_data  = text_data[:split_idx]\n",
    "val_data    = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfd0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_dataloader_v1\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "  train_data,\n",
    "  batch_size=2,\n",
    "  max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "  stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "  drop_last=True,\n",
    "  shuffle=True,\n",
    "  num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "  val_data,\n",
    "  batch_size=2,\n",
    "  max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "  stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "  drop_last=False,\n",
    "  shuffle=False,\n",
    "  num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eece9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "  print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "  print(x.shape, y.shape)\n",
    "  # print(x)\n",
    "  # print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "  input_batch = input_batch.to(device)\n",
    "  target_batch = target_batch.to(device)\n",
    "  logits = model(input_batch)\n",
    "  loss = torch.nn.functional.cross_entropy(\n",
    "    logits.flatten(0, 1), target_batch.flatten()\n",
    "  )\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 5-2\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "  total_loss = 0.\n",
    "  if len(data_loader) == 0:\n",
    "    return float(\"nan\")\n",
    "  elif num_batches is None:\n",
    "    num_batches = len(data_loader)\n",
    "  else:\n",
    "    num_batches = min(num_batches, len(data_loader))\n",
    "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "    if i < num_batches:\n",
    "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "      total_loss += loss.item()\n",
    "    else:\n",
    "      break\n",
    "  return total_loss/num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  train_loss  = calc_loss_loader(train_loader, model, device)\n",
    "  val_loss    = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss    :\", train_loss)\n",
    "print(\"Validataion loss :\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f0798",
   "metadata": {},
   "source": [
    "## 5.2 LLMを訓練する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    train_loss  = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "    val_loss    = calc_loss_loader(val_loader,   model, device, num_batches=eval_iter)\n",
    "\n",
    "  model.train()\n",
    "  return train_loss, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "  model.eval()\n",
    "  context_size = model.pos_emb.weight.shape[0]\n",
    "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "  with torch.no_grad():\n",
    "    token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=50, context_size=context_size)\n",
    "\n",
    "  decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "  print(decoded_text.replace(\"\\n\", \" \"))\n",
    "  model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 5-3\n",
    "\n",
    "def train_model_simple( model, train_loader, val_loader, optimizer, device,\n",
    "                        num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "  tokens_seen, global_step = 0, -1\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for input_batch, target_batch in train_loader:\n",
    "      optimizer.zero_grad()\n",
    "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      tokens_seen += input_batch.numel()\n",
    "      global_step += 1\n",
    "\n",
    "      if global_step % eval_freq == 0:\n",
    "        train_loss, val_loss = evaluate_model( model, train_loader, val_loader, device, eval_iter)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        track_tokens_seen.append(tokens_seen)\n",
    "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "              f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        \n",
    "    generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "  return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "  model, train_loader, val_loader, optimizer, device,\n",
    "  num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "  start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4306c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epoches_seen, tokens_seen, trains_losses, val_losses):\n",
    "  fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "  ax1.plot(epoches_seen, train_losses, label=\"Training loss\")\n",
    "  ax1.plot(epoches_seen, val_losses, linestyle=\"-.\", label=\"Validataion loss\")\n",
    "  ax1.set_xlabel(\"Epochs\")\n",
    "  ax1.set_ylabel(\"Loss\")\n",
    "  ax1.legend(loc=\"upper right\")\n",
    "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "  ax2 = ax1.twiny()\n",
    "  ax2.plot(tokens_seen, trains_losses, alpha=0)\n",
    "  ax2.set_xlabel(\"Tokens seen\")\n",
    "  fig.tight_layout()\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01458b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6efcc2",
   "metadata": {},
   "source": [
    "## 5.3 ランダム性をコントロールするデコーディング戦略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49caad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple( model=model, idx=text_to_token_ids(\"Every effort moves you\", tokenizer), \n",
    "                                  max_new_tokens=25, context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973b5e7",
   "metadata": {},
   "source": [
    "### 温度スケーリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba053f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "  \"closer\": 0,\n",
    "  \"every\": 1,\n",
    "  \"effort\": 2,\n",
    "  \"forward\": 3,\n",
    "  \"inches\": 4,\n",
    "  \"moves\": 5,\n",
    "  \"pizza\": 6,\n",
    "  \"toward\": 7,\n",
    "  \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "  [4.51, 0.89, -1.9, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4113895",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fa181",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "  torch.manual_seed(123)\n",
    "  sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1000)]\n",
    "  sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "  for i, freq in enumerate(sampled_ids):\n",
    "    print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9be60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "  scaled_logits = logits / temperature\n",
    "  return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5287a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probs = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperatures):\n",
    "  rects = ax.bar(x + i * bar_width, scaled_probs[i], bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37d3cc",
   "metadata": {},
   "source": [
    "### top-k サンプリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68558353",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logits = torch.where(\n",
    "  condition=next_token_logits < top_logits[-1],\n",
    "  input=torch.tensor(float('-inf')),\n",
    "  other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fde126",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd71885",
   "metadata": {},
   "source": [
    "### テキスト生成関数を修正する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af488b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 5-4\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "  for _ in range(max_new_tokens):\n",
    "    idx_cond = idx[:, -context_size:]\n",
    "    with torch.no_grad():\n",
    "      logits = model(idx_cond)\n",
    "    logits = logits[:, -1, :]\n",
    "\n",
    "    if top_k is not None:\n",
    "      top_logits, _ = torch.topk(logits, top_k)\n",
    "      min_val = top_logits[:,-1]\n",
    "      logits = torch.where(\n",
    "        logits < min_val,\n",
    "        torch.tensor(float('-inf')).to(logits.device),\n",
    "        logits\n",
    "      )\n",
    "    \n",
    "    if temperature > 0.0:\n",
    "      logits = logits / temperature\n",
    "      probas = torch.softmax(logits, dim=-1)\n",
    "      idx_next = torch.multinomial(probas, num_samples=1)\n",
    "    else:\n",
    "      idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "    if idx_next == eos_id:\n",
    "      break\n",
    "\n",
    "    idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "  return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "  model=model,\n",
    "  idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "  max_new_tokens=15,\n",
    "  context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "  top_k=25,\n",
    "  temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e0c66b",
   "metadata": {},
   "source": [
    "## 5.4 PyTorchでのモデルの重みの保存と読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff44150",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2518238",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizerの状態も保存\n",
    "torch.save({\n",
    "  \"model_state_dict\": model.state_dict(),\n",
    "  \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "  },\n",
    "  \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a60c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10bbfc2",
   "metadata": {},
   "source": [
    "## 5.5 OpenAI から事前学習済みの重みを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_download.py\"\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02349973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c32609",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding wight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "  \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "  \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "  \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "  \"gpt2-x1 (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef246a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ab2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "  if left.shape != right.shape:\n",
    "    raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "  return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e590d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 5-5\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "  gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "  gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "  for b in range(len(params[\"blocks\"])):\n",
    "    q_w, k_w, v_w = np.split(\n",
    "      params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1)\n",
    "    gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "      gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "    gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "      gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "    gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "      gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "    \n",
    "    q_b, k_b, v_b = np.split(\n",
    "      params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1)\n",
    "    gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "      gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "    gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "      gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "    gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "      gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "    \n",
    "    gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "      gpt.trf_blocks[b].att.out_proj.weight,\n",
    "      params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "    \n",
    "    gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "      gpt.trf_blocks[b].att.out_proj.bias,\n",
    "      params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "    \n",
    "    gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "      gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "      params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "    gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "      gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "      params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "    gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "      gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "      params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "    gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "      gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "      params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "    \n",
    "    gpt.trf_blocks[b].norm1.scale = assign(\n",
    "      gpt.trf_blocks[b].norm1.scale,\n",
    "      params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "    gpt.trf_blocks[b].norm1.shift = assign(\n",
    "      gpt.trf_blocks[b].norm1.shift,\n",
    "      params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "    gpt.trf_blocks[b].norm2.scale = assign(\n",
    "      gpt.trf_blocks[b].norm2.scale,\n",
    "      params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "    gpt.trf_blocks[b].norm2.shift = assign(\n",
    "      gpt.trf_blocks[b].norm2.shift,\n",
    "      params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "  gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "  gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "  gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f34427",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b414742",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "  model=gpt,\n",
    "  idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "  max_new_tokens=25,\n",
    "  context_size=NEW_CONFIG[\"context_length\"],\n",
    "  top_k=50,\n",
    "  temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0f642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
